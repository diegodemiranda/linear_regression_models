{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/t09dXNbx5BkIl92Fr7Vy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegodemiranda/linear_regression_models/blob/main/chicago_taxi_fare_prediction/linear_regression_chicago_taxi_fare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Linear Regression - Chicago Taxi fare ride\n",
        "\n",
        "With this notebook we will use a dataset to train a model to predict the fare of a taxi ride in Chicago, Illinois."
      ],
      "metadata": {
        "id": "O9NOMZ5zwHo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Setup the Environment\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oit-sCvix_D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load dependencies\n",
        "\n",
        "The model depends on several Python libraries to help with data manipulation, machine learning tasks, and data visualization."
      ],
      "metadata": {
        "id": "emmsv1sQvBh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxj5ep4-urZt"
      },
      "outputs": [],
      "source": [
        "#general\n",
        "import io\n",
        "\n",
        "# data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "\n",
        "# data visualization\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the dataset\n",
        "The following code cell loads the dataset and creates a pandas DataFrame."
      ],
      "metadata": {
        "id": "M-6A7uErvECm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chicago_taxi_dataset = pd.read_csv(\"chicago_taxi_train.csv\")\n",
        "\n",
        "training_df = chicago_taxi_dataset[['TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE']]\n",
        "\n",
        "print('Read dataset completed successfully.')\n",
        "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
        "\n",
        "training_df.head(200)"
      ],
      "metadata": {
        "id": "C-DC6VTXu8hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Dataset Exploration\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UAcbzkl0yI1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View dataset statistics\n",
        "\n",
        " In this step, I will use the `DataFrame.describe` method to view **descriptive statistics** about the dataset and answer some important questions about the data."
      ],
      "metadata": {
        "id": "bUtbZj7xyxv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.describe(include='all')"
      ],
      "metadata": {
        "id": "Tu8SzOv_yOFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View correlation matrix and visualize relationships with pair plot\n",
        "\n",
        "In this step, I will use a **correlation matrix** to identify features whose values correlate well with the label. In essence, finding out how strongly related the numerical features of the taxi trip data are to each other.\n",
        "\n",
        "Correlation values have the following meanings:\n",
        "\n",
        "* **+1**: Perfect positive correlation (as one feature increases, the other increases proportionally)\n",
        "* **-1**: Perfect negative correlation (as one feature increases, the other decreases proportionally)\n",
        "* **0**: No linear correlation (no relationship between the features).\n",
        "\n",
        "In general, the higher the absolute value of a correlation value, the greater its predictive power.\n",
        "The correlation **does not imply causality**. The correlation matrix only captures **linear relationships**. If the relationship between the variables is non-linear, the correlation can be close to 0, even if there is a strong relationship."
      ],
      "metadata": {
        "id": "7tRzsuN94l42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.corr(numeric_only = True)"
      ],
      "metadata": {
        "id": "Tltcz7uj4Oqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **pair plot** generates a grid of pairwise plots to visualize the relationship of each feature with all other features all in one place.\n",
        "Pair plots help us quickly identify **correlations, patterns, distribution and outliers**.\n",
        "This visualization helps you understand our data better and guide us next steps in the machine learning process."
      ],
      "metadata": {
        "id": "ebdn_lRsS29n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(training_df, x_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"], y_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"])"
      ],
      "metadata": {
        "id": "TlVo0F16S-9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Train Model\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "T8jvUXLyWjJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining plotting functions\n",
        "\n",
        "To help us visualize the results of each training run we will generate two plots at the end of each experiment:\n",
        "\n",
        "* a **scatter plot** of the features vs. the label with a line showing the output of the trained model;\n",
        "* a **loss curve**;"
      ],
      "metadata": {
        "id": "MF3DuGBJXAEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_plots(df, feature_names, label_name, model_output, sample_size=200):\n",
        "\n",
        "  random_sample = df.sample(n=sample_size).copy()\n",
        "  random_sample.reset_index()\n",
        "  weights, bias, epochs, rmse = model_output\n",
        "\n",
        "  is_2d_plot = len(feature_names) == 1\n",
        "  model_plot_type = \"scatter\" if is_2d_plot else \"surface\"\n",
        "  fig = make_subplots(rows=1, cols=2,\n",
        "                      subplot_titles=(\"Loss Curve\", \"Model Plot\"),\n",
        "                      specs=[[{\"type\": \"scatter\"}, {\"type\": model_plot_type}]])\n",
        "\n",
        "  plot_data(random_sample, feature_names, label_name, fig)\n",
        "  plot_model(random_sample, feature_names, weights, bias, fig)\n",
        "  plot_loss_curve(epochs, rmse, fig)\n",
        "\n",
        "  fig.show()\n",
        "  return\n",
        "\n",
        "def plot_loss_curve(epochs, rmse, fig):\n",
        "  curve = px.line(x=epochs, y=rmse)\n",
        "  curve.update_traces(line_color='#ff0000', line_width=3)\n",
        "\n",
        "  fig.append_trace(curve.data[0], row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\"Root Mean Squared Error\", row=1, col=1, range=[rmse.min()*0.8, rmse.max()])\n",
        "\n",
        "  return\n",
        "\n",
        "def plot_data(df, features, label, fig):\n",
        "  if len(features) == 1:\n",
        "    scatter = px.scatter(df, x=features[0], y=label)\n",
        "  else:\n",
        "    scatter = px.scatter_3d(df, x=features[0], y=features[1], z=label)\n",
        "\n",
        "  fig.append_trace(scatter.data[0], row=1, col=2)\n",
        "  if len(features) == 1:\n",
        "    fig.update_xaxes(title_text=features[0], row=1, col=2)\n",
        "    fig.update_yaxes(title_text=label, row=1, col=2)\n",
        "  else:\n",
        "    fig.update_layout(scene1=dict(xaxis_title=features[0], yaxis_title=features[1], zaxis_title=label))\n",
        "\n",
        "  return\n",
        "\n",
        "def plot_model(df, features, weights, bias, fig):\n",
        "  df['FARE_PREDICTED'] = bias[0]\n",
        "\n",
        "  for index, feature in enumerate(features):\n",
        "    df['FARE_PREDICTED'] = df['FARE_PREDICTED'] + weights[index][0] * df[feature]\n",
        "\n",
        "  if len(features) == 1:\n",
        "    model = px.line(df, x=features[0], y='FARE_PREDICTED')\n",
        "    model.update_traces(line_color='#ff0000', line_width=3)\n",
        "  else:\n",
        "    z_name, y_name = \"FARE_PREDICTED\", features[1]\n",
        "    z = [df[z_name].min(), (df[z_name].max() - df[z_name].min()) / 2, df[z_name].max()]\n",
        "    y = [df[y_name].min(), (df[y_name].max() - df[y_name].min()) / 2, df[y_name].max()]\n",
        "    x = []\n",
        "    for i in range(len(y)):\n",
        "      x.append((z[i] - weights[1][0] * y[i] - bias[0]) / weights[0][0])\n",
        "\n",
        "    plane=pd.DataFrame({'x':x, 'y':y, 'z':[z] * 3})\n",
        "\n",
        "    light_yellow = [[0, '#89CFF0'], [1, '#FFDB58']]\n",
        "    model = go.Figure(data=go.Surface(x=plane['x'], y=plane['y'], z=plane['z'],\n",
        "                                      colorscale=light_yellow))\n",
        "\n",
        "  fig.add_trace(model.data[0], row=1, col=2)\n",
        "\n",
        "  return\n",
        "\n",
        "def model_info(feature_names, label_name, model_output):\n",
        "  weights = model_output[0]\n",
        "  bias = model_output[1]\n",
        "\n",
        "  nl = \"\\n\"\n",
        "  header = \"-\" * 80\n",
        "  banner = header + nl + \"|\" + \"MODEL INFO\".center(78) + \"|\" + nl + header\n",
        "\n",
        "  info = \"\"\n",
        "  equation = label_name + \" = \"\n",
        "\n",
        "  for index, feature in enumerate(feature_names):\n",
        "    info = info + \"Weight for feature[{}]: {:.3f}\\n\".format(feature, weights[index][0])\n",
        "    equation = equation + \"{:.3f} * {} + \".format(weights[index][0], feature)\n",
        "\n",
        "  info = info + \"Bias: {:.3f}\\n\".format(bias[0])\n",
        "  equation = equation + \"{:.3f}\\n\".format(bias[0])\n",
        "\n",
        "  return banner + nl + info + nl + equation\n",
        "\n",
        "print(\"Success: defining plotting functions complete.\")"
      ],
      "metadata": {
        "id": "fGxY5hhdW98f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining functions to build and train a model\n",
        "\n",
        "The code you need to build and train your model is in the **Define ML functions** code cell. If you would like to explore this code, expand the code cell and take a look."
      ],
      "metadata": {
        "id": "VWvX2UccXiII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(my_learning_rate, num_features):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  inputs = keras.Input(shape=(num_features,))\n",
        "  outputs = keras.layers.Dense(units=1)(inputs)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  # Compile the model topography into code that Keras can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, df, features, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the model the feature and the label.\n",
        "  # The model will train for the specified number of epochs.\n",
        "  # input_x = df.iloc[:,1:3].values\n",
        "  # df[feature]\n",
        "  history = model.fit(x=features,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # To track the progression of training, we're going to take a snapshot\n",
        "  # of the model's root mean squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "\n",
        "def run_experiment(df, feature_names, label_name, learning_rate, epochs, batch_size):\n",
        "\n",
        "  print('Info: starting training experiment with features={} and label={}\\n'.format(feature_names, label_name))\n",
        "\n",
        "  num_features = len(feature_names)\n",
        "\n",
        "  features = df.loc[:, feature_names].values\n",
        "  label = df[label_name].values\n",
        "\n",
        "  model = build_model(learning_rate, num_features)\n",
        "  model_output = train_model(model, df, features, label, epochs, batch_size)\n",
        "\n",
        "  print('\\nSuccess: training experiment complete\\n')\n",
        "  print('{}'.format(model_info(feature_names, label_name, model_output)))\n",
        "  make_plots(df, feature_names, label_name, model_output)\n",
        "\n",
        "  return model\n",
        "\n",
        "print(\"Success: defining linear regression functions complete.\")"
      ],
      "metadata": {
        "id": "tG8zwUlpYAkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a model with one feature\n",
        "\n",
        "In this step we will train a model to predict the cost of the fare using a single feature. Earlier, we saw that `TRIP_MILES` (distance) correlates **most strongly** with the `FARE`, so let's start with `TRIP_MILES` as the feature for our first training run.\n",
        "\n",
        "During training, we should see the **root mean square error (RMSE)** in the output. The units for RMSE are the same as the units for the label (dollars). In other words, we can use the RMSE to determine how far off, on average, the predicted fares are in dollars from the observed values."
      ],
      "metadata": {
        "id": "dNtr6Q1HY8qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 50\n",
        "\n",
        "# Specify the feature and the label.\n",
        "features = ['TRIP_MILES']\n",
        "label = 'FARE'\n",
        "\n",
        "model_1 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
      ],
      "metadata": {
        "id": "okRnhKB2Zehk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}